{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6208c1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset-1: AMAZON FASHION \treviews (883,636 reviews)\tmetadata (186,637 products)\n",
    "# Dataset-2: All Beauty \treviews (371,345 reviews)\tmetadata (32,992 products)\n",
    "# Dataset-3: Appliances \treviews (602,777 reviews)\tmetadata (30,459 products)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "#nltk.download('vader_lexicon')\n",
    "import nltk.corpus\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "from collections import Counter\n",
    "\"\"\"\n",
    "from google.colab import drive\n",
    "# This will prompt for authorization.\n",
    "drive.mount('/content/drive')\n",
    "!ls \"/content/drive/MyDrive/Review\"\n",
    "\n",
    "data = [json.loads(line) for line in open('/content/drive/MyDrive/Review/Magazine_Subscriptions.json', 'r')]\n",
    "print(len(data))\n",
    "for item in data:\n",
    "  data['overall'].value_count() \n",
    "\"\"\"\n",
    "\n",
    "data = [json.loads(line) for line in open('Appliances.json', 'r')]\n",
    "no_data=len(data)\n",
    "\n",
    "i=0\n",
    "overall=[None]*no_data\n",
    "reviewText=[None]*no_data\n",
    "reviewScore=0\n",
    "\n",
    "for item in data:\n",
    "    if \"reviewText\" in item:\n",
    "        overall[i]=item['overall']\n",
    "        reviewText[i]=item['reviewText']\n",
    "        reviewScore+=overall[i]\n",
    "        i=i+1\n",
    "    else:\n",
    "        no_data-=1\n",
    "        \n",
    "print(no_data)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30b7332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sample_review = reviewText[:no_data]\n",
    "\n",
    "sentiment = SentimentIntensityAnalyzer()\n",
    "\n",
    "f=open('sentiment.txt', 'w')\n",
    "count=0\n",
    "avg_rating=0\n",
    "comp_rating=0\n",
    "for sentences in sample_review:\n",
    "    sentences\n",
    "    ss = sentiment.polarity_scores(sentences)\n",
    "    \n",
    "    #to get compound, negetive, neutral, positive score\n",
    "    for k in sorted(ss):\n",
    "        compound_score =ss['compound']\n",
    "        #print(f\"ss: {compound_score}\")\n",
    "    #f.write(f\"ss[{count}]:{(compound_score+1)/2.0*5.0}\\n\")\n",
    "    \n",
    "    avg_rating+=(compound_score+1)/2.0*5.0\n",
    "    comp_rating+=(overall[count]+compound_score/5.0)*(5/6)\n",
    "    #f.write(sentences)\n",
    "    #f.write(\"\\n\")\n",
    "    count+=1\n",
    "    \n",
    "     \n",
    "    \"\"\"    \n",
    "        print('{0}: {1}, '.format(k, ss[k]))\n",
    "    print(sentences)   \n",
    "   \n",
    "    \"\"\"\n",
    "f.close()\n",
    "review_NLP = avg_rating/no_data\n",
    "review_Score= reviewScore/no_data\n",
    "comp_rating=comp_rating/no_data\n",
    "print(f\"Review analysis score: {review_Score}\")\n",
    "print(f\"Review analysis score using NLP: {review_NLP}\")\n",
    "print(f\"Review analysis score tuning Using NLP: {comp_rating}\")\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff0db0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Forecasting with ARIMA#############\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from pmdarima.arima import ARIMA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data from JSON\n",
    "data = [json.loads(line) for line in open('Appliances.json', 'r')]\n",
    "\n",
    "# Convert JSON data to a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Preprocess the data if needed (e.g., convert date/time columns, handle missing values)\n",
    "##############\n",
    "df.rename({'Time': 'unixReviewTime', 'Sales': 'reviewerID'}, axis=1, inplace=True)\n",
    "df = df[['unixReviewTime', 'reviewerID']].groupby(['unixReviewTime']).agg(['count'])\n",
    "df = df.reset_index()\n",
    "df['unixReviewTime'] = df['unixReviewTime'].astype(int)\n",
    "############\n",
    "\n",
    "# Set the column names for date and target variable\n",
    "date_column = 'unixReviewTime'\n",
    "target_column = 'reviewerID'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convert the date column to datetime type\n",
    "df[date_column] = pd.to_datetime(df[date_column])\n",
    "\n",
    "# Set the date column as the DataFrame index\n",
    "df.set_index(date_column, inplace=True)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_size = int(0.8 * len(df))\n",
    "train_data = df.iloc[:train_size]\n",
    "test_data = df.iloc[train_size:]\n",
    "\n",
    "# Fit the ARIMA model\n",
    "order = (1, 1, 1)  # Specify the order of the ARIMA model (p, d, q)\n",
    "model = ARIMA(order=order)\n",
    "model_fit = model.fit(train_data[target_column].values)\n",
    "\n",
    "# Forecast future values with 30% confidence interval\n",
    "forecast_values, conf_int = model_fit.predict(n_periods=len(test_data), return_conf_int=True, alpha=0.3)\n",
    "\n",
    "# Create a DataFrame for the forecast values\n",
    "forecast_df = pd.DataFrame(forecast_values, columns=['forecast'])\n",
    "forecast_df.index = test_data.index\n",
    "\n",
    "# Combine the forecast DataFrame with the original test_data DataFrame\n",
    "forecast_data = pd.concat([test_data, forecast_df], axis=1)\n",
    "\n",
    "# Plot the train data as a line graph\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_data.index, train_data[target_column], label='Train Data', linewidth=2)\n",
    "\n",
    "# Plot the forecasted values with 30% confidence interval\n",
    "plt.plot(forecast_data.index, forecast_data['forecast'], label='Forecast')\n",
    "plt.fill_between(forecast_data.index, conf_int[:, 0], conf_int[:, 1], alpha=0.3)\n",
    "\n",
    "\n",
    "plt.xlabel('Unix Time')\n",
    "plt.ylabel('Sales')\n",
    "plt.title('ARIMA Forecast (with 30% confidence value)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a67a22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ARIMA MAPE Value #############\n",
    "actual_values = test_data[target_column].values\n",
    "mape = (abs(actual_values - forecast_values) / actual_values).mean() * 100\n",
    "print(f\"MAPE using ARIMA: {mape:.3f}\")\n",
    "\n",
    "##### ARIMA MAPE Value using customer's review score #############\n",
    "actual_values = (test_data[target_column].values)\n",
    "mape = (abs(actual_values - (forecast_values * (review_Score/5) ))/ actual_values).mean() * 100\n",
    "print(f\"MAPE using ARIMA with review score: {mape:.3f}\")\n",
    "\n",
    "##### ARIMA MAPE Value using customer's review text #############\n",
    "actual_values = (test_data[target_column].values)\n",
    "mape = (abs(actual_values - (forecast_values * (review_NLP/5) )) / actual_values).mean() * 100\n",
    "print(f\"MAPE using ARIMA with review text: {mape:.3f}\")\n",
    "\n",
    "##### ARIMA MAPE Value using customer's review Score tuning #############\n",
    "actual_values = (test_data[target_column].values)\n",
    "mape = (abs(actual_values - (forecast_values * (comp_rating/5) )) / actual_values).mean() * 100\n",
    "print(f\"MAPE using ARIMA with review score tuning: {mape:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd70e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSLE (Mean Squared Logarithmic Error)\n",
    "msle = np.mean(np.log1p((actual_values - forecast_values) ** 2))\n",
    "print(f\"MSLE using ARIMA: {msle:.3f}\")\n",
    "\n",
    "##### ARIMA MSLE Value using customer's review score #############\n",
    "msle = np.mean(np.log1p((actual_values - forecast_values * (review_Score/5)) ** 2))\n",
    "print(f\"MSLE using ARIMA with review score: {msle:.3f}\")\n",
    "\n",
    "##### ARIMA MSLE Value using customer's review text #############\n",
    "msle = np.mean(np.log1p((actual_values - forecast_values * (review_NLP/5)) ** 2))\n",
    "print(f\"MSLE using ARIMA with review text: {msle:.3f}\")\n",
    "\n",
    "##### ARIMA MSLE Value using customer's review Score tuning #############\n",
    "msle = np.mean(np.log1p((actual_values - forecast_values * (comp_rating/5)) ** 2))\n",
    "print(f\"MSLE using ARIMA with review score tuning: {msle:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078505a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Fit in SARIMA ###########\n",
    "import json\n",
    "import pandas as pd\n",
    "from pmdarima.arima import ARIMA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data from JSON\n",
    "data = [json.loads(line) for line in open('Appliances.json', 'r')]\n",
    "\n",
    "# Convert JSON data to a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Preprocess the data if needed (e.g., convert date/time columns, handle missing values)\n",
    "##############\n",
    "df.rename({'review_time': 'unixReviewTime', 'product_id': 'reviewerID'}, axis=1, inplace=True)\n",
    "        \n",
    "df = df[['unixReviewTime', 'reviewerID']].groupby(['unixReviewTime']).agg(['count'])\n",
    "df = df.reset_index()\n",
    "df['unixReviewTime'] = df['unixReviewTime'].astype(int)\n",
    "\n",
    "############\n",
    "\n",
    "# Set the column names for date and target variable\n",
    "date_column = 'unixReviewTime'\n",
    "target_column = 'reviewerID'\n",
    "\n",
    "# Convert the date column to datetime type\n",
    "df[date_column] = pd.to_datetime(df[date_column])\n",
    "\n",
    "# Set the date column as the DataFrame index\n",
    "df.set_index(date_column, inplace=True)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_size = int(0.8 * len(df))\n",
    "train_data = df.iloc[:train_size]\n",
    "test_data = df.iloc[train_size:]\n",
    "\n",
    "# Fit the SARIMA model\n",
    "order = (1, 1, 1)  # Specify the order of the ARIMA model (p, d, q)\n",
    "seasonal_order = (1, 0, 1, 12)  # Specify the seasonal order of the SARIMA model (P, D, Q, S)\n",
    "\n",
    "SARIMA = ARIMA(order=order, seasonal_order=seasonal_order)\n",
    "model_fit = SARIMA.fit(train_data[target_column].values)\n",
    "\n",
    "# Forecast future values for the test data\n",
    "forecast_values, conf_int = model_fit.predict(n_periods=len(test_data), return_conf_int=True, alpha=0.3)\n",
    "\n",
    "# Create a DataFrame for the forecast values\n",
    "forecast_df = pd.DataFrame(forecast_values, columns=['forecast'])\n",
    "forecast_df.index = test_data.index\n",
    "\n",
    "# Combine the forecast DataFrame with the original test_data DataFrame\n",
    "forecast_data = pd.concat([test_data, forecast_df], axis=1)\n",
    "\n",
    "# Plot the forecast and confidence interval for the test data\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_data.index, train_data[target_column], label='Train Data')\n",
    "plt.plot(test_data.index, forecast_data['forecast'], label='Forecast')\n",
    "plt.fill_between(test_data.index, conf_int[:, 0], conf_int[:, 1], alpha=0.3, color='gray', label='Confidence Interval')\n",
    "plt.xlabel('Unix Time')\n",
    "plt.ylabel('Sales')\n",
    "plt.title('SARIMA Forecast (with 30% confidence value)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3073447",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SARIMA MAPE Value #############\n",
    "actual_values = test_data[target_column].values\n",
    "mape = (abs(actual_values - forecast_values) / actual_values).mean() * 100\n",
    "print(f\"MAPE using SARIMA: {mape:.3f}\")\n",
    "\n",
    "##### SARIMA MAPE Value using customer's review score #############\n",
    "actual_values = (test_data[target_column].values)\n",
    "mape = (abs(actual_values - (forecast_values * (review_Score/5) ))/ actual_values).mean() * 100\n",
    "print(f\"MAPE using SARIMA with review score: {mape:.3f}\")\n",
    "\n",
    "##### SARIMA MAPE Value using customer's review text #############\n",
    "actual_values = (test_data[target_column].values)\n",
    "mape = (abs(actual_values - (forecast_values * (review_NLP/5) )) / actual_values).mean() * 100\n",
    "print(f\"MAPE using SARIMA with review text: {mape:.3f}\")\n",
    "\n",
    "##### SARIMA MAPE Value using customer's review score tuning #############\n",
    "actual_values = (test_data[target_column].values)\n",
    "mape = (abs(actual_values - (forecast_values * (comp_rating/5) )) / actual_values).mean() * 100\n",
    "print(f\"MAPE using SARIMA with review score tuning: {mape:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7b49d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSLE (Mean Squared Logarithmic Error)\n",
    "msle = np.mean(np.log1p((actual_values - forecast_values) ** 2))\n",
    "print(f\"MSLE using SARIMA: {msle:.3f}\")\n",
    "\n",
    "##### SARIMA MSLE Value using customer's review score #############\n",
    "msle = np.mean(np.log1p((actual_values - forecast_values * (review_Score/5)) ** 2))\n",
    "print(f\"MSLE using SARIMA with review score: {msle:.3f}\")\n",
    "\n",
    "##### SARIMA MSLE Value using customer's review text #############\n",
    "msle = np.mean(np.log1p((actual_values - forecast_values * (review_NLP/5)) ** 2))\n",
    "print(f\"MSLE using SARIMA with review text: {msle:.3f}\")\n",
    "\n",
    "##### SARIMA MSLE Value using customer's review score tuning #############\n",
    "msle = np.mean(np.log1p((actual_values - forecast_values * (comp_rating/5)) ** 2))\n",
    "print(f\"MSLE using SARIMA with review score tuning: {msle:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff510f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LSTM model ########\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Load the data from JSON\n",
    "data = [json.loads(line) for line in open('Appliances.json', 'r')]\n",
    "\n",
    "# Convert JSON data to a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Preprocess the data if needed (e.g., convert date/time columns, handle missing values)\n",
    "##############\n",
    "df.rename({'review_time': 'unixReviewTime', 'product_id': 'reviewerID'}, axis=1, inplace=True)\n",
    "        \n",
    "df = df[['unixReviewTime', 'reviewerID']].groupby(['unixReviewTime']).agg(['count'])\n",
    "df = df.reset_index()\n",
    "df['unixReviewTime'] = df['unixReviewTime'].astype(int)\n",
    "\n",
    "############\n",
    "\n",
    "# Set the column names for date and target variable\n",
    "date_column = 'unixReviewTime'\n",
    "target_column = 'reviewerID'\n",
    "\n",
    "# Convert the date column to datetime type\n",
    "df[date_column] = pd.to_datetime(df[date_column])\n",
    "\n",
    "# Set the date column as the DataFrame index\n",
    "df.set_index(date_column, inplace=True)\n",
    "\n",
    "# Extract the target variable data\n",
    "target_data = df[target_column].values.reshape(-1, 1)\n",
    "\n",
    "# Scale the target variable to the range of 0 to 1\n",
    "scaler = MinMaxScaler()\n",
    "scaled_target_data = scaler.fit_transform(target_data)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_size = int(0.8 * len(df))\n",
    "train_data = scaled_target_data[:train_size]\n",
    "test_data = scaled_target_data[train_size:]\n",
    "\n",
    "# Define the window size for input sequence\n",
    "window_size = 10\n",
    "\n",
    "# Prepare the training data\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(window_size, len(train_data)):\n",
    "    X_train.append(train_data[i - window_size:i, 0])\n",
    "    y_train.append(train_data[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "# Reshape the input data for LSTM\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, activation='relu', input_shape=(window_size, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the LSTM model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32)\n",
    "\n",
    "# Prepare the test data\n",
    "X_test = []\n",
    "y_test = []\n",
    "for i in range(window_size, len(test_data)):\n",
    "    X_test.append(test_data[i - window_size:i, 0])\n",
    "    y_test.append(test_data[i, 0])\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "# Reshape the input data for LSTM\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Make predictions with the LSTM model\n",
    "predicted_data = model.predict(X_test)\n",
    "predicted_data = scaler.inverse_transform(predicted_data)\n",
    "\n",
    "# Create a DataFrame for the predicted values\n",
    "predicted_df = pd.DataFrame(predicted_data, index=df.index[train_size+window_size:], columns=['predicted'])\n",
    "\n",
    "# Plot the actual and predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df.index, df[target_column], label='Actual')\n",
    "plt.plot(predicted_df.index, predicted_df['predicted'], color='red', label='Predicted')\n",
    "plt.xlabel(date_column)\n",
    "plt.ylabel(target_column)\n",
    "plt.title('LSTM Forecast')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8551676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MAPE\n",
    "def calculate_mape(actual, predicted):\n",
    "    return np.mean(np.abs((actual - predicted) / actual)) * 100\n",
    "\n",
    "# Convert the actual and predicted data to numpy arrays\n",
    "actual_data = df[target_column].values[train_size+window_size:]\n",
    "predicted_data = predicted_df['predicted'].values\n",
    "\n",
    "# Calculate MAPE\n",
    "mape = calculate_mape(actual_data, predicted_data)\n",
    "print(f\"MAPE using LSTM: {mape:.3f}\")\n",
    "\n",
    "# Calculate MAPE using Review Score\n",
    "mape_score = calculate_mape(actual_data, predicted_data* (review_Score/5))\n",
    "print(f\"MAPE using LSTM with review score: {mape_score:.3f}\")\n",
    "\n",
    "# Calculate MAPE using Review Text\n",
    "mape_NLP = calculate_mape(actual_data, predicted_data* (review_NLP/5))\n",
    "print(f\"MAPE using LSTM with review text: {mape_NLP:.3f}\")\n",
    "\n",
    "# Calculate MAPE using Review Score tuning\n",
    "mape_scoreTune = calculate_mape(actual_data, predicted_data* (comp_rating/5))\n",
    "print(f\"MAPE using LSTM with review score tuning: {mape_scoreTune:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2838d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSLE\n",
    "def calculate_msle(actual, predicted):\n",
    "    return np.mean(np.square(np.log1p(actual) - np.log1p(predicted)))\n",
    "\n",
    "# Calculate MSLE\n",
    "msle = calculate_msle(actual_data, predicted_data)\n",
    "print(f\"MSLE using LSTM: {msle:.3f}\")\n",
    "\n",
    "msle_score = calculate_msle(actual_data, predicted_data * (review_Score/5))\n",
    "print(f\"MSLE using LSTM with review score: {msle_score:.3f}\")\n",
    "\n",
    "msle_NLP = calculate_msle(actual_data, predicted_data * (review_NLP/5))\n",
    "print(f\"MSLE using LSTM with review text: {msle_NLP:.3f}\")\n",
    "\n",
    "mape_scoreTune =calculate_msle(actual_data, predicted_data * (comp_rating/5))\n",
    "print(f\"MSLE using LSTM with review score tuning: {mape_scoreTune:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
